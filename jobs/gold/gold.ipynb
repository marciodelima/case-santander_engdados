{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JOB - CAMADA GOLD\n",
    "\n",
    "## Sumarização de dados, KPIs de Negocio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#Conf para o parquet - HIVE\n",
    "from pyspark.conf import SparkConf\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.sql.parquet.writeLegacyFormat\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria a sessão Spark\n",
    "spark = SparkSession.builder.appName('pipeline-gold').master(\"local\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega os dados a partir do HDFS - Silver\n",
    "dadosCli = spark.read.parquet(\"hdfs://34.151.243.241:9000/datalake/silver/clientes/\")\n",
    "dadosVei = spark.read.parquet(\"hdfs://34.151.243.241:9000/datalake/silver/veiculos/\")\n",
    "dadosDes = spark.read.parquet(\"hdfs://34.151.243.241:9000/datalake/silver/despachantes/\")\n",
    "dadosLoc = spark.read.parquet(\"hdfs://34.151.243.241:9000/datalake/silver/locacao/\")\n",
    "dadosContratos = spark.read.parquet(\"hdfs://34.151.243.241:9000/datalake/silver/contratos/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformação dos dados de Negocio\n",
    "\n",
    "dadosCli.createOrReplaceTempView(\"clientes\")\n",
    "dadosVei.createOrReplaceTempView(\"veiculos\")\n",
    "dadosDes.createOrReplaceTempView(\"despachantes\")\n",
    "dadosLoc.createOrReplaceTempView(\"locacao\")\n",
    "dadosContratos.createOrReplaceTempView(\"contratos\")\n",
    "\n",
    "#Veiculos locados em periodos\n",
    "dadosLocacaoVei = spark.sql (\"\"\" SELECT veic.MODELO AS MODELO, YEAR(loc.DATALOCACAO) as ANO, \n",
    "MONTH(loc.DATALOCACAO) as MES, COUNT(*) as TOTAL from locacao loc \n",
    "JOIN veiculos veic on (veic.IDVEICULO = loc.IDVEICULO) \n",
    "GROUP BY veic.MODELO, YEAR(loc.DATALOCACAO), MONTH(loc.DATALOCACAO) \n",
    "order by TOTAL DESC\n",
    "        \"\"\")\n",
    "\n",
    "#Despachantes por locacao e Veiculos\n",
    "dadosLocacaoDes = spark.sql (\"\"\" SELECT desp.IDDESPACHANTE as ID, veic.MODELO AS MODELO, \n",
    "YEAR(loc.DATALOCACAO) as ANO, MONTH(loc.DATALOCACAO) as MES, COUNT(loc.TOTAL) as TOTAL \n",
    "from locacao loc JOIN veiculos veic on (loc.IDVEICULO = veic.IDVEICULO)  \n",
    "JOIN despachantes desp on (loc.IDDESPACHANTE = loc.IDDESPACHANTE) \n",
    "GROUP BY desp.IDDESPACHANTE, veic.MODELO, YEAR(loc.DATALOCACAO), MONTH(loc.DATALOCACAO) \n",
    "order by TOTAL DESC \"\"\")\n",
    "\n",
    "#Faturamento no Periodo\n",
    "dadosFaturamento = spark.sql (\"\"\" SELECT YEAR(loc.DATALOCACAO) as ANO, MONTH(loc.DATALOCACAO) as MES, \n",
    "                             SUM(loc.TOTAL) as TOTAL from locacao loc \n",
    "                             GROUP BY MONTH(loc.DATALOCACAO), YEAR(loc.DATALOCACAO) order by ANO, MES \"\"\")\n",
    "\n",
    "#Quantidade de Locacao por Clientes - Mensal\n",
    "dadosLocacaoCli = spark.sql (\"\"\" \n",
    "        SELECT cli.IDCLIENTE as ID, MONTH(loc.DATALOCACAO) as MES, YEAR(loc.DATALOCACAO) as ANO, count(*) as TOTAL \n",
    "        from locacao loc join clientes cli on (cli.IDCLIENTE = loc.IDCLIENTE) \n",
    "        GROUP BY cli.IDCLIENTE, MONTH(loc.DATALOCACAO), YEAR(loc.DATALOCACAO) order by cli.IDCLIENTE, ANO, MES \n",
    "        \"\"\")\n",
    "\n",
    "#Listagem dos Contratos de Risco\n",
    "dadosRisco = spark.sql (\"\"\" \n",
    "        SELECT con.IDCONTRATO AS ID, con.IDCLIENTE as IDCLIENTE from contratos con\n",
    "        WHERE con.CONTRATO like '%risco%' order by con.IDCONTRATO DESC\n",
    "        \"\"\")\n",
    "\n",
    "dadosLocacaoCli.coalesce(1)\n",
    "dadosLocacaoVei.coalesce(1)\n",
    "dadosLocacaoDes.coalesce(1)\n",
    "dadosFaturamento.coalesce(1)                             \n",
    "dadosRisco.coalesce(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gravacao - Camada GOLD\n",
    "dadosLocacaoCli.write.mode(\"overwrite\").parquet(\"hdfs://34.151.243.241:9000/datalake/gold/locacaoClientes/\") \n",
    "dadosLocacaoVei.write.mode(\"overwrite\").parquet(\"hdfs://34.151.243.241:9000/datalake/gold/locacaoVeiculos/\")\n",
    "dadosLocacaoDes.write.mode(\"overwrite\").parquet(\"hdfs://34.151.243.241:9000/datalake/gold/locacaoDespachantes/\")\n",
    "dadosFaturamento.write.mode(\"overwrite\").parquet(\"hdfs://34.151.243.241:9000/datalake/gold/faturamento/\")\n",
    "dadosRisco.write.mode(\"overwrite\").parquet(\"hdfs://34.151.243.241:9000/datalake/gold/contratosRisco/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
